{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK3  Prompt Engineering for Large Language Models (LLMs)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from langchain_groq.chat_models import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Retrieving API key from environment variable\n",
    "Groq_Token = os.getenv('GROQ_API_KEY')  \n",
    "\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 3 QUESTION 1**\n",
    "\n",
    "Demonstrate how to use Zero-Shot Learning and Few-Shot Learning to classify human activities based on the featurized accelerometer data. Qualitatively demonstrate the performance of Few-Shot Learning with Zero-Shot Learning. Which method performs better? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing the train data into batched and caluclating the batches statistics and storing them in a dataframe along with the activity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       mean_x     std_x    mean_y     std_y    mean_z     std_z  \\\n",
      "0    0.204124  0.048866  0.783937  0.038701  0.570764  0.033825   \n",
      "1    0.000232  0.217422  0.392028  0.394234  0.767831  0.217310   \n",
      "2    0.224066  0.079934  0.883928  0.072199  0.109092  0.369246   \n",
      "3    0.120071  0.019850  0.937430  0.011048 -0.327627  0.046894   \n",
      "4    0.242744  0.003633  0.950401  0.003133  0.177047  0.007601   \n",
      "..        ...       ...       ...       ...       ...       ...   \n",
      "530  0.945478  0.241143 -0.288449  0.125674 -0.312030  0.146582   \n",
      "531  0.933012  0.227146 -0.291454  0.114674 -0.344396  0.139293   \n",
      "532  0.974438  0.274445 -0.312021  0.215679 -0.014065  0.181421   \n",
      "533  0.926365  0.267540 -0.272930  0.234719 -0.256930  0.278965   \n",
      "534  0.908850  0.267274 -0.242411  0.245716 -0.411538  0.216363   \n",
      "\n",
      "             Activity         Subject  \n",
      "0              LAYING   Subject_1.csv  \n",
      "1              LAYING   Subject_1.csv  \n",
      "2              LAYING   Subject_1.csv  \n",
      "3              LAYING   Subject_1.csv  \n",
      "4              LAYING  Subject_11.csv  \n",
      "..                ...             ...  \n",
      "530  WALKING_UPSTAIRS   Subject_7.csv  \n",
      "531  WALKING_UPSTAIRS   Subject_7.csv  \n",
      "532  WALKING_UPSTAIRS   Subject_8.csv  \n",
      "533  WALKING_UPSTAIRS   Subject_8.csv  \n",
      "534  WALKING_UPSTAIRS   Subject_8.csv  \n",
      "\n",
      "[535 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def compute_statistics(batch, activity, subject):\n",
    "    stats = {\n",
    "        'mean_x': np.mean(batch['accx']),\n",
    "        'std_x': np.std(batch['accx']),\n",
    "        'mean_y': np.mean(batch['accy']),\n",
    "        'std_y': np.std(batch['accy']),\n",
    "        'mean_z': np.mean(batch['accz']),\n",
    "        'std_z': np.std(batch['accz']),\n",
    "        'Activity': activity,\n",
    "        'Subject': subject\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "\n",
    "def load_data_in_batches(file_path, batch_size):\n",
    "    \n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Split data into batches\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data.iloc[i:i+batch_size]\n",
    "        yield {\n",
    "            'accx': batch['accx'].values,\n",
    "            'accy': batch['accy'].values,\n",
    "            'accz': batch['accz'].values\n",
    "        }\n",
    "\n",
    "\n",
    "all_features = []\n",
    "\n",
    "\n",
    "root_dir = 'C:\\\\Users\\\\DELL ADMIN\\\\OneDrive - iitgn.ac.in\\\\Desktop\\\\HAR_GROQ\\\\Combined\\\\Train'\n",
    "\n",
    "\n",
    "for activity_folder in os.listdir(root_dir):\n",
    "    activity_path = os.path.join(root_dir, activity_folder)\n",
    "    \n",
    "    \n",
    "    for subject_folder in os.listdir(activity_path):\n",
    "        subject_path = os.path.join(activity_path, subject_folder)\n",
    "        subject = subject_folder  # Use the folder name as the subject label\n",
    "\n",
    "        \n",
    "        for batch in load_data_in_batches(subject_path, batch_size=1000):\n",
    "            batch_features = compute_statistics(batch, activity_folder, subject)\n",
    "            all_features.append(batch_features)\n",
    "\n",
    "# Converting the list of features into a DataFrame\n",
    "features_df_train = pd.DataFrame(all_features)\n",
    "print(features_df_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing the test data into batched and caluclating the batches statistics and storing them in a dataframe along with the activity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       mean_x     std_x    mean_y     std_y    mean_z     std_z  \\\n",
      "0    0.028797  0.018906  0.933876  0.121222  0.245238  0.240399   \n",
      "1   -0.062842  0.017220  0.244647  0.150631 -0.955031  0.174157   \n",
      "2    0.053585  0.010768 -0.946899  0.026178  0.364380  0.062999   \n",
      "3    0.052172  0.008300 -0.979769  0.005028  0.280589  0.005341   \n",
      "4    0.080302  0.036276  0.579530  0.034168  0.806016  0.023551   \n",
      "..        ...       ...       ...       ...       ...       ...   \n",
      "211  0.992572  0.265286 -0.213564  0.153276  0.080797  0.122088   \n",
      "212  1.005808  0.176179 -0.127162  0.119899 -0.155315  0.111018   \n",
      "213  0.981737  0.207003 -0.058746  0.161851 -0.245872  0.161213   \n",
      "214  0.921280  0.239340  0.094504  0.106363 -0.404641  0.161947   \n",
      "215  0.933048  0.240656  0.106210  0.091837 -0.420244  0.179441   \n",
      "\n",
      "             Activity         Subject  \n",
      "0              LAYING  Subject_10.csv  \n",
      "1              LAYING  Subject_10.csv  \n",
      "2              LAYING  Subject_10.csv  \n",
      "3              LAYING  Subject_10.csv  \n",
      "4              LAYING  Subject_12.csv  \n",
      "..                ...             ...  \n",
      "211  WALKING_UPSTAIRS   Subject_4.csv  \n",
      "212  WALKING_UPSTAIRS   Subject_9.csv  \n",
      "213  WALKING_UPSTAIRS   Subject_9.csv  \n",
      "214  WALKING_UPSTAIRS   Subject_9.csv  \n",
      "215  WALKING_UPSTAIRS   Subject_9.csv  \n",
      "\n",
      "[216 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to compute statistics for each batch\n",
    "def compute_statistics(batch, activity, subject):\n",
    "    stats = {\n",
    "        'mean_x': np.mean(batch['accx']),\n",
    "        'std_x': np.std(batch['accx']),\n",
    "        'mean_y': np.mean(batch['accy']),\n",
    "        'std_y': np.std(batch['accy']),\n",
    "        'mean_z': np.mean(batch['accz']),\n",
    "        'std_z': np.std(batch['accz']),\n",
    "        'Activity': activity,\n",
    "        'Subject': subject\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "# function to make data in batches\n",
    "def load_data_in_batches(file_path, batch_size):\n",
    "    \n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    \n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data.iloc[i:i+batch_size]\n",
    "        yield {\n",
    "            'accx': batch['accx'].values,\n",
    "            'accy': batch['accy'].values,\n",
    "            'accz': batch['accz'].values\n",
    "        }\n",
    "\n",
    "\n",
    "all_features = []\n",
    "\n",
    "\n",
    "root_dir = 'C:\\\\Users\\\\DELL ADMIN\\\\OneDrive - iitgn.ac.in\\\\Desktop\\\\HAR_GROQ\\\\Combined\\\\Test'\n",
    "\n",
    "# Looping over each activity folder\n",
    "for activity_folder in os.listdir(root_dir):\n",
    "    activity_path = os.path.join(root_dir, activity_folder)\n",
    "    \n",
    "    # Looping over each subject folder within the activity folder\n",
    "    for subject_folder in os.listdir(activity_path):\n",
    "        subject_path = os.path.join(activity_path, subject_folder)\n",
    "        subject = subject_folder  # Use the folder name as the subject label\n",
    "\n",
    "        # Processing data in batches\n",
    "        for batch in load_data_in_batches(subject_path, batch_size=1000):\n",
    "            batch_features = compute_statistics(batch, activity_folder, subject)\n",
    "            all_features.append(batch_features)\n",
    "\n",
    "# Converting the list of features into a DataFrame\n",
    "features_df_test = pd.DataFrame(all_features)\n",
    "print(features_df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZERO SHOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took test data and predicted by zero shot learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Activity  predicted_activity\n",
      "0              LAYING  Walking_Downstairs\n",
      "1              LAYING            Standing\n",
      "2              LAYING  Walking_Downstairs\n",
      "3              LAYING            Standing\n",
      "4              LAYING  Walking_Downstairs\n",
      "..                ...                 ...\n",
      "211  WALKING_UPSTAIRS             Walking\n",
      "212  WALKING_UPSTAIRS             Walking\n",
      "213  WALKING_UPSTAIRS             Walking\n",
      "214  WALKING_UPSTAIRS  Walking_Downstairs\n",
      "215  WALKING_UPSTAIRS  Walking_Downstairs\n",
      "\n",
      "[216 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx, row in features_df_test.iterrows():\n",
    "    # Extracting the features for the current row\n",
    "    mean_x = row['mean_x']\n",
    "    mean_y = row['mean_y']\n",
    "    mean_z = row['mean_z']\n",
    "    std_x = row['std_x']\n",
    "    std_y = row['std_y']\n",
    "    std_z = row['std_z']\n",
    "\n",
    "    # Generating the prompt using the features\n",
    "    query = f\"\"\"\n",
    "    * You are a classification model for human activities based on accelerometer data.\n",
    "    * Classify the following data into one of the six activities: 'walking', 'Laying', 'sitting', 'Walking_Upstairs', 'Walking_Downstairs', 'Standing'.\n",
    "    * Data: Mean x={mean_x:.2f}, Mean y={mean_y:.2f}, Mean z={mean_z:.2f}, Std x={std_x:.2f}, Std y={std_y:.2f}, Std z={std_z:.2f}.\n",
    "    * Provide only the activity name as your response, without any explanation.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    model_name = \"llama3-70b\" \n",
    "    llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "    answer = llm.invoke(query)\n",
    "\n",
    "    \n",
    "    predicted_activity = answer.content.strip()\n",
    "\n",
    "    \n",
    "    features_df_test.loc[idx, 'predicted_activity'] = predicted_activity\n",
    "\n",
    "print(features_df_test[['Activity', 'predicted_activity']])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEW SHOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took test data and predicted by Few shot learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples_df\n",
      "['SITTING', 'LAYING', 'LAYING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'LAYING', 'SITTING', 'STANDING', 'WALKING']\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "             Activity predicted_activity_few\n",
      "0              LAYING                 LAYING\n",
      "1              LAYING     WALKING_DOWNSTAIRS\n",
      "2              LAYING                 LAYING\n",
      "3              LAYING                 LAYING\n",
      "4              LAYING                 LAYING\n",
      "..                ...                    ...\n",
      "211  WALKING_UPSTAIRS                WALKING\n",
      "212  WALKING_UPSTAIRS     WALKING_DOWNSTAIRS\n",
      "213  WALKING_UPSTAIRS     WALKING_DOWNSTAIRS\n",
      "214  WALKING_UPSTAIRS     WALKING_DOWNSTAIRS\n",
      "215  WALKING_UPSTAIRS     WALKING_DOWNSTAIRS\n",
      "\n",
      "[216 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Taking samples from train dataframe from few shot and using test for predicting\n",
    "examples_df = features_df_train.sample(10)\n",
    "print(\"examples_df\")\n",
    "# printing what activities are choosen\n",
    "print(examples_df[\"Activity\"].to_list()) \n",
    "test_df = features_df_test.copy()  \n",
    "\n",
    "# Generating the examples part of the prompt\n",
    "examples_str = \"\"\n",
    "for idx, row in examples_df.iterrows():\n",
    "    mean_x, mean_y, mean_z = row['mean_x'], row['mean_y'], row['mean_z']\n",
    "    std_x, std_y, std_z = row['std_x'], row['std_y'], row['std_z']\n",
    "    activity = row['Activity']\n",
    "    examples_str += f\"Example {idx+1}:\\n\"\n",
    "    examples_str += f\"Data: Mean x={mean_x:.2f}, Mean y={mean_y:.2f}, Mean z={mean_z:.2f}, Std x={std_x:.2f}, Std y={std_y:.2f}, Std z={std_z:.2f}\\n\"\n",
    "    examples_str += f\"Activity: {activity}\\n\\n\"\n",
    "\n",
    "# Iterating over the test DataFrame\n",
    "for idx, row in test_df.iterrows():\n",
    "    mean_x, mean_y, mean_z = row['mean_x'], row['mean_y'], row['mean_z']\n",
    "    std_x, std_y, std_z = row['std_x'], row['std_y'], row['std_z']\n",
    "    print(idx)\n",
    "\n",
    "    # Creating the query prompt with examples and the new data to classify\n",
    "    query = f\"\"\"\n",
    "    * You are a classification model for human activities based on accelerometer data.\n",
    "    * Classify the following data into one of the six activities: 'walking', 'Laying', 'sitting', 'standing', 'Walking Downstairs', 'Walking Upstairs'.\n",
    "    * Use the examples below as guidance.\n",
    "    * Provide only the activity name as your response, without any explanation.\n",
    "\n",
    "    {examples_str}\n",
    "\n",
    "    Now, classify this new data:\n",
    "    * Data: Mean x={mean_x:.2f}, Mean y={mean_y:.2f}, Mean z={mean_z:.2f}, Std x={std_x:.2f}, Std y={std_y:.2f}, Std z={std_z:.2f}.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    answer = llm.invoke(query)\n",
    "\n",
    "    \n",
    "    predicted_activity = answer.content.strip()\n",
    "\n",
    "    \n",
    "    test_df.loc[idx, 'predicted_activity_few'] = predicted_activity\n",
    "\n",
    "\n",
    "print(test_df[['Activity', 'predicted_activity_few']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing Zero shot and Few shot learinng**\n",
    "\n",
    "In FSL, the model is provided with a few labeled examples of the new class, enabling it to directly learn the distinctive features and patterns associated with that class. This direct exposure helps the model to develop a more precise and nuanced understanding of the new class, leading to better performance.\n",
    "\n",
    "Without direct examples, ZSL struggles with specificity. The model may recognize general patterns but lacks the detail-oriented approach needed to differentiate closely related activities. This can lead to errors, particularly in tasks requiring fine-grained distinctions.\n",
    "\n",
    "In summary, Few-Shot Learningâ€™s capability to directly learn from a few examples makes it more accurate, robust, and adaptable, providing a clear advantage over Zero-Shot Learning, especially in practical applications. While ZSL offers an intriguing solution when no examples are available, its limitations in generalization and accuracy make it less suitable for most real-world scenarios where some data, even if limited, can be obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 3 Question 2**\n",
    "\n",
    "Quantitatively compare the accuracy of Few-Shot Learning with Decision Trees (You may use a subset of the test set if you encounter rate-limiting issues). Which method performs better? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "X_train = features_df_train[['mean_x', 'std_x', 'mean_y', 'std_y', 'mean_z', 'std_z']]\n",
    "y_train = features_df_train['Activity']\n",
    "\n",
    "X_test = features_df_test[['mean_x', 'std_x', 'mean_y', 'std_y', 'mean_z', 'std_z']]\n",
    "y_test = features_df_test['Activity']\n",
    "\n",
    "# Training the Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred_tree = clf.predict(X_test)\n",
    "\n",
    "\n",
    "if y_test.dtype != y_pred_tree.dtype:\n",
    "    y_test = y_test.astype(str)\n",
    "\n",
    "# Calculating accuracy\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "print(f\"Decision Tree Accuracy: {accuracy_tree:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-Shot Learning Accuracy: 0.47\n"
     ]
    }
   ],
   "source": [
    "# Calculating accuracy for Few-Shot Learning\n",
    "accuracy_few_shot = accuracy_score(test_df['Activity'], test_df['predicted_activity_few'])\n",
    "print(f\"Few-Shot Learning Accuracy: {accuracy_few_shot:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, the higher accuracy of Decision Trees suggests that the dataset was well-suited to the decision-making process of this model, possibly due to clear separability in the feature space or effective tuning of the tree's hyperparameters. The FSL model, while powerful in scenarios with very few examples, might not have been the best fit for the data you were working with, especially if it wasn't optimized for the larger dataset size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 3 Question 3**\n",
    "\n",
    "What are the limitations of Zero-Shot Learning and Few-Shot Learning in the context of classifying human activities based on featurized accelerometer data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limitations of Zero-Shot Learning (ZSL) in Classifying Human Activities**\n",
    "\n",
    "1. Lack of Specific Data:\n",
    "   ZSL struggles because it relies on semantic relationships between known and unknown classes, which might not be strong enough for accurately classifying complex or subtle human activities. Without direct examples, the model may misclassify activities that have similar movement patterns but different meanings.\n",
    "\n",
    "2. Semantic Gap:\n",
    "   The model must infer relationships between seen and unseen classes based on prior knowledge, which can lead to errors if the unseen activity doesn't share significant features with known activities. For example, jumping might be misclassified as running if the model hasn't been trained on jumping data, as both involve dynamic movement.\n",
    "\n",
    "**Limitations of Few-Shot Learning (FSL) in Classifying Human Activities**\n",
    "\n",
    "1. Dependence on Quality of Few Examples:\n",
    "   FSL's performance heavily depends on the quality and representativeness of the few examples provided. If the few samples of a new activity aren't diverse enough, the model might overfit to these examples and fail to generalize well to unseen data.\n",
    "\n",
    "2. Sensitivity to Noise:\n",
    "   With only a few examples, FSL is more susceptible to noise or outliers in the data, which can significantly affect model performance. Inaccurate or noisy accelerometer readings can lead to incorrect classification if they dominate the few samples available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 3 Question 4**\n",
    "\n",
    "What does the model classify when given input from an entirely new activity that it hasn't seen before? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-shot examples:\n",
      "['SITTING', 'WALKING', 'SITTING', 'STANDING', 'SITTING']\n",
      "       Activity predicted_activity_few\n",
      "0  new_activity                 LAYING\n",
      "1  new_activity                 LAYING\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# taking samples from train for few shot learning\n",
    "examples_df = features_df_train.sample(5)  # Few-shot examples\n",
    "print(\"Few-shot examples:\")\n",
    "print(examples_df[\"Activity\"].to_list())\n",
    "\n",
    "\n",
    "new_activity_data = {\n",
    "    'mean_x': [0.3, 0.35],\n",
    "    'std_x': [0.04, 0.045],\n",
    "    'mean_y': [0.1, 0.15],\n",
    "    'std_y': [0.02, 0.025],\n",
    "    'mean_z': [0.25, 0.3],\n",
    "    'std_z': [0.03, 0.035],\n",
    "    'Activity': ['new_activity', 'new_activity']  # Label for the new activity\n",
    "}\n",
    "\n",
    "new_activity_df = pd.DataFrame(new_activity_data)\n",
    "\n",
    "# Combining with the few-shot examples to observe behavior\n",
    "test_df = new_activity_df.copy()\n",
    "\n",
    "# Generating few-shot examples prompt\n",
    "examples_str = \"\"\n",
    "for idx, row in examples_df.iterrows():\n",
    "    mean_x, mean_y, mean_z = row['mean_x'], row['mean_y'], row['mean_z']\n",
    "    std_x, std_y, std_z = row['std_x'], row['std_y'], row['std_z']\n",
    "    activity = row['Activity']\n",
    "    examples_str += f\"Example {idx+1}:\\n\"\n",
    "    examples_str += f\"Data: Mean x={mean_x:.2f}, Mean y={mean_y:.2f}, Mean z={mean_z:.2f}, Std x={std_x:.2f}, Std y={std_y:.2f}, Std z={std_z:.2f}\\n\"\n",
    "    examples_str += f\"Activity: {activity}\\n\\n\"\n",
    "\n",
    "# Iterating over the new activity dataset\n",
    "for idx, row in test_df.iterrows():\n",
    "    mean_x, mean_y, mean_z = row['mean_x'], row['mean_y'], row['mean_z']\n",
    "    std_x, std_y, std_z = row['std_x'], row['std_y'], row['std_z']\n",
    "\n",
    "    # Creating the query prompt for the few-shot model\n",
    "    query = f\"\"\"\n",
    "    You are a classification model for human activities based on accelerometer data.\n",
    "    Classify the following data into one of the six activities: 'walking', 'laying', 'sitting', 'standing', 'walking downstairs', 'walking upstairs'.\n",
    "    Use the examples below as guidance.\n",
    "    Provide only the activity name as your response, without any explanation.\n",
    "\n",
    "    {examples_str}\n",
    "\n",
    "    Now, classify this new data:\n",
    "    Data: Mean x={mean_x:.2f}, Mean y={mean_y:.2f}, Mean z={mean_z:.2f}, Std x={std_x:.2f}, Std y={std_y:.2f}, Std z={std_z:.2f}.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    try:\n",
    "        predicted_activity = llm.invoke(query).content.strip()  # Replace with the LLM's response\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        predicted_activity = \"Error\"\n",
    "\n",
    "    \n",
    "    test_df.loc[idx, 'predicted_activity_few'] = predicted_activity\n",
    "\n",
    "\n",
    "print(test_df[['Activity', 'predicted_activity_few']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FSL models are designed to handle new classes with minimal examples, so they should classify new inputs related to the activities they have been trained on. For completely new activities not represented in the few-shot examples, the model may struggle and could classify the input as one of the closest known classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 3 Question 5**\n",
    "\n",
    "Test the model with random data (ensuring the data has the same dimensions and range as the previous input) and report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-shot examples:\n",
      "['WALKING', 'STANDING', 'STANDING', 'LAYING', 'WALKING_UPSTAIRS']\n",
      "    predicted_activity_few\n",
      "0         WALKING_UPSTAIRS\n",
      "1         WALKING_UPSTAIRS\n",
      "2       WALKING_DOWNSTAIRS\n",
      "3       WALKING_DOWNSTAIRS\n",
      "4       WALKING_DOWNSTAIRS\n",
      "..                     ...\n",
      "211     WALKING_DOWNSTAIRS\n",
      "212                SITTING\n",
      "213     WALKING_DOWNSTAIRS\n",
      "214     WALKING_DOWNSTAIRS\n",
      "215                 LAYING\n",
      "\n",
      "[216 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# using samples from features_df_train for few shot training\n",
    "examples_df = features_df_train.sample(5)  # Few-shot examples\n",
    "print(\"Few-shot examples:\")\n",
    "print(examples_df[\"Activity\"].to_list())\n",
    "\n",
    "\n",
    "num_random_samples = 216  # Number of random samples\n",
    "random_data = {\n",
    "    'mean_x': np.random.uniform(features_df_train['mean_x'].min(), features_df_train['mean_x'].max(), num_random_samples),\n",
    "    'std_x': np.random.uniform(features_df_train['std_x'].min(), features_df_train['std_x'].max(), num_random_samples),\n",
    "    'mean_y': np.random.uniform(features_df_train['mean_y'].min(), features_df_train['mean_y'].max(), num_random_samples),\n",
    "    'std_y': np.random.uniform(features_df_train['std_y'].min(), features_df_train['std_y'].max(), num_random_samples),\n",
    "    'mean_z': np.random.uniform(features_df_train['mean_z'].min(), features_df_train['mean_z'].max(), num_random_samples),\n",
    "    'std_z': np.random.uniform(features_df_train['std_z'].min(), features_df_train['std_z'].max(), num_random_samples)\n",
    "}\n",
    "\n",
    "random_df = pd.DataFrame(random_data)\n",
    "\n",
    "\n",
    "test_df = random_df.copy()\n",
    "\n",
    "# Generating few-shot examples prompt\n",
    "examples_str = \"\"\n",
    "for idx, row in examples_df.iterrows():\n",
    "    mean_x, mean_y, mean_z = row['mean_x'], row['mean_y'], row['mean_z']\n",
    "    std_x, std_y, std_z = row['std_x'], row['std_y'], row['std_z']\n",
    "    activity = row['Activity']\n",
    "    examples_str += f\"Example {idx+1}:\\n\"\n",
    "    examples_str += f\"Data: Mean x={mean_x:.2f}, Mean y={mean_y:.2f}, Mean z={mean_z:.2f}, Std x={std_x:.2f}, Std y={std_y:.2f}, Std z={std_z:.2f}\\n\"\n",
    "    examples_str += f\"Activity: {activity}\\n\\n\"\n",
    "\n",
    "\n",
    "test_df['predicted_activity_few'] = \"\"\n",
    "\n",
    "# Iterating over the random dataset\n",
    "for idx, row in test_df.iterrows():\n",
    "    mean_x, mean_y, mean_z = row['mean_x'], row['mean_y'], row['mean_z']\n",
    "    std_x, std_y, std_z = row['std_x'], row['std_y'], row['std_z']\n",
    "\n",
    "    # Creating the query prompt for the few-shot model\n",
    "    query = f\"\"\"\n",
    "    You are a classification model for human activities based on accelerometer data.\n",
    "    Classify the following data into one of the six activities: 'walking', 'laying', 'sitting', 'standing', 'walking downstairs', 'walking upstairs'.\n",
    "    Use the examples below as guidance.\n",
    "    Provide only the activity name as your response, without any explanation.\n",
    "\n",
    "    {examples_str}\n",
    "\n",
    "    Now, classify this new data:\n",
    "    Data: Mean x={mean_x:.2f}, Mean y={mean_y:.2f}, Mean z={mean_z:.2f}, Std x={std_x:.2f}, Std y={std_y:.2f}, Std z={std_z:.2f}.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    predicted_activity = llm.invoke(query).content.strip()  # Replace with actual model invocation\n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "    test_df.loc[idx, 'predicted_activity_few'] = predicted_activity\n",
    "\n",
    "\n",
    "print(test_df[['predicted_activity_few']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
